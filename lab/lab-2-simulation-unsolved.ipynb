{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 7.1, 7.3, 7.4, 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 8.1, 8.4, 8.2, 8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "RNG = np.random.default_rng(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Two servers failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the example from the lecture in which two servers have a failure probability $p_1$ and $p_2$, respectively, on any given day.\n",
    "\n",
    "Complete the steps below to:\n",
    "- compare the probability of the first server failing before the second based on the formula and simulation;\n",
    "- investigate the effect of the number of simulated scenarios on the accuracy of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, have two functions that each take $p_1$ and $p_2$ as parameters and calculate the expectation and, respectively, variance for the first server failing before the second via the corresponding formula.\n",
    "\n",
    "**Note**: You have seen the expectation formula during the lecture, while for the variance, you can reuse the expectation value and the fact that, like a Bernoulli, the distribution has only values of zero or one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_first_fails_before_second(p_1: float, p_2: float) -> float:\n",
    "    ...\n",
    "\n",
    "def var_first_fails_before_second(p_1: float, p_2: float) -> float:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a detour, use the expectation formula to plot the probability of the first server failing before the second for every combination of $p_1 \\leftarrow 0.1, \\, 0.2, \\, ... \\, 0.9$ and $p_2 \\leftarrow 0.1, \\, 0.2, \\, ... \\, 0.9$, with the marker size at each coordinate pair being the probability multiplied by 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_p_fail_first: Axes\n",
    "fig_p_fail_first, ax_p_fail_first = plt.subplots()\n",
    "ax_p_fail_first.set_title(\"P(server 1 fails before second server 2)\")\n",
    "ax_p_fail_first.set_xlabel(\"p_1\")\n",
    "ax_p_fail_first.set_ylabel(\"p_2\")\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous lab, define a function that finds the mean and variance from an array of samples by only using subtraction, multiplication, exponentiation, and sum operators instead of directly calling the bespoke `numpy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mean(samples: np.ndarray) -> np.floating:\n",
    "    return samples.sum() / samples.size\n",
    "\n",
    "def estimate_var(samples: np.ndarray) -> np.floating:\n",
    "    est_mean = estimate_mean(samples)\n",
    "    samples_shifted = samples - est_mean\n",
    "    samples_shifted_squared = samples_shifted ** 2\n",
    "\n",
    "    return samples_shifted_squared.sum() / samples.size\n",
    "    # Alternatively:\n",
    "    # return (samples ** 2).sum() / samples.size - est_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that takes in the number of trials $t$, alongside $p_1$ and $p_2$, to return an integer array with the outcomes of the trials.\n",
    "\n",
    "Determine the correct distribution for the servers and use `RNG` to sample from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_servers(t: int, p_1: float, p_2: float) -> np.ndarray:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $p_1=0.2$ and $p_2=0.3$.\n",
    "\n",
    "Compare the mean/variance calculated via the formula, to those estimated from $T = 100 ( = 1e2)$ simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1, p_2 = 0.2, 0.3\n",
    "true_mean = mean_first_fails_before_second(p_1, p_2)\n",
    "true_var = var_first_fails_before_second(p_1, p_2)\n",
    "t_few = int(1e2)\n",
    "sim_outcomes_few = simulate_servers(t_few, p_1, p_2)\n",
    "est_mean_few = estimate_mean(sim_outcomes_few)\n",
    "est_var_few = estimate_var(sim_outcomes_few)\n",
    "\n",
    "print(\n",
    "    f\"T={t_few}\",\n",
    "    f\"True mean: {true_mean}\",\n",
    "    f\"Estimated mean: {est_mean_few}\",\n",
    "    f\"Absolute difference: {abs(true_mean - est_mean_few)}\",\n",
    "    f\"True variance: {true_var}\",\n",
    "    f\"Estimated variance: {est_var_few}\",\n",
    "    f\"Absolute difference: {abs(true_var - est_var_few)}\",\n",
    "    sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the comparison for $T=10,000,000 (= 1e7)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_many = int(1e7)\n",
    "sim_outcomes_many = simulate_servers(t_many, p_1, p_2)\n",
    "est_mean_many = estimate_mean(sim_outcomes_many)\n",
    "est_var_many = estimate_var(sim_outcomes_many)\n",
    "\n",
    "print(\n",
    "    f\"T={t_many}\",\n",
    "    f\"Estimated mean: {est_mean_many}\",\n",
    "    f\"Absolute difference: {abs(true_mean - est_mean_many)}\",\n",
    "    f\"Estimated variance: {est_var_many}\",\n",
    "    f\"Absolute difference: {abs(true_var - est_var_many)}\",\n",
    "    sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still for the same $p_1$ and $p_2$, calculate the absolute error of the mean for $t \\leftarrow 1e1, \\, ..., \\, 1e4$, repeating the process 10 times for each value of $t$.\n",
    "\n",
    "After, plot a line through the average outcome for each value of $t$, also shading the area from the min/max towards the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_error: Axes\n",
    "fig_error, ax_error = plt.subplots()\n",
    "ax_error.set_title(\"Error for the mean estimate\")\n",
    "ax_error.set_xlabel(\"t\")\n",
    "ax_error.set_ylabel(\"| Error |\")\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Memorylessness in continuous distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the lecture that memorylessness describes random variables $X$ for which knowing $\\mathbf{P}(X > s)$ does not change the outcome of $\\mathbf{P}(X >  t + s \\, | \\, X > s)$ from that of $\\mathbf{P}(X > t)$ regardless of the $s > 0$ and $t > 0$.\n",
    "\n",
    "Complete the steps below to empirically check that the property holds for any arbitrarily given instance of the exponential family but not the uniform one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that one way of confirming memorylessness is by checking whether $[X \\, | \\, X > s]$ has the same distribution as $s + X$ for all $s > 0$.\n",
    "\n",
    "Thus, start by defining a simulation function that takes in an array of samples and $s$, returning a tuple with only the samples greater than $s$, and all the original samples increased by $s$.\n",
    "\n",
    "Discard, in either of the two lists, values that are greater than the max value in the other list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_memorylessness(samples: np.ndarray, s: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that takes in the samples for $[X \\, | \\, X > s]$ and $s + X$ and plots the two distributions over each other.\n",
    "\n",
    "Use `numpy`'s `histogram` function, with `bins=\"auto\"` to create histogram data from the $[X \\, | \\, X > s]$ samples and normalize the resulting array so that its entries sum up to one; do the same for the $s + X$ samples, but pass as `bins` those from the previous call; for drawing each distribution, you can use the `stairs` function in `Axes`/`pyplot`.\n",
    "\n",
    "**Note**: $[X \\, | \\, X > s]$ will have more samples than $s + X$, but that is acceptable as long as that number of samples is still large enough (e.g., in the thousands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_memorylessness(\n",
    "        samples_gr_s: np.ndarray, samples_plus_s: np.ndarray) -> Figure:\n",
    "    ax: Axes\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Distributions of discretized [X | x > s] & s + X\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"P(X = x)\")\n",
    "    ax.set_xmargin(0.0)\n",
    "    ...\n",
    "    ax.legend()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take $T = 5e7$ samples from an exponential distribution with $\\lambda = 2$ and visually confirm that memorylessness holds when $s = 4$.\n",
    "\n",
    "**Note**: The `exponential` distribution in numpy takes in a $\\beta$ parameter via the `scale` argument, which equals $\\frac{1}{\\lambda}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_memorylessness, s_memorylessness = int(5e7), 4\n",
    "lambda_exp = 2\n",
    "samples_exp = RNG.exponential(scale=1/lambda_exp, size=t_memorylessness)\n",
    "samples_gr_s_exp, samples_plus_s_exp = simulate_memorylessness(\n",
    "    samples_exp, s_memorylessness)\n",
    "fig_memorylessness_exp = plot_memorylessness(samples_gr_s_exp, samples_plus_s_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same $T$ and $s$ as before, visually confirm that memorylessness does not hold for a uniform distribution with $a = 1$ and $b = 7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1, 7\n",
    "samples_uniform = RNG.uniform(low=a, high=b, size=t_memorylessness)\n",
    "samples_gr_s_uniform, samples_plus_s_uniform = simulate_memorylessness(\n",
    "    samples_uniform, s_memorylessness)\n",
    "fig_memorylessness_uniform = plot_memorylessness(samples_gr_s_uniform, samples_plus_s_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conditional expectation of computing jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the general setting of the lecture exercises where computing jobs with size (in CPU hours) sampled from some continuous distribution are sent to bin 1 if they are smaller than some value $V$ or dispatched to bin 2 otherwise.\n",
    "\n",
    "Complete the steps below to:\n",
    "- verify through simulation the values obtained for the specific scenario solved in class;\n",
    "- empirically answer the same questions for different variants of the problem scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function which, given as input an array of samples and a size $s$, returns the instances that are lower than $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_under_v(samples: np.ndarray, v: float) -> np.ndarray:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function above, define functions that estimate from an given sample array and $V$:\n",
    "- $P(\\text{job is in bin 1})$\n",
    "- $P(\\text{job size} < W \\, | \\, \\text{job is in bin 1})$ with $W (< V)$ also given\n",
    "- $E[\\text{job size} ,\\ | \\, \\text{job is in bin 1}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_prob_bin_1(samples: np.ndarray, v: float) -> float:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_prob_under_q_if_bin_1(samples: np.ndarray, v: float, w: float) -> float:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_mean_size_if_bin_1(samples: np.ndarray, v: float) -> float:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample $t= 1e7$ times from an exponential distribution of job sizes with *mean* 1000, set $V = 500$, and $W = 200$, then compute the estimates for the three quantities above, cross-referencing with the lecture results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_jobs = int(1e7)\n",
    "v_lect = 500\n",
    "w_lect = 200\n",
    "samples_lect = RNG.exponential(scale=1000, size=t_jobs)\n",
    "estimated_prob_bin_1_lect = est_prob_bin_1(samples_lect, v_lect)\n",
    "estimated_prob_under_q_if_bin_1_lect = est_prob_under_q_if_bin_1(samples_lect, v_lect, w_lect)\n",
    "estimated_mean_size_if_bin_1_lect = est_mean_size_if_bin_1(samples_lect, v_lect)\n",
    "print(\n",
    "    f\"P(job is in bin 1) = {estimated_prob_bin_1_lect:.4f}\",\n",
    "    f\"P(job size < W | job is in bin 1) = {estimated_prob_under_q_if_bin_1_lect:.4f}\",\n",
    "    f\"E[job size | job is in bin 1] = {estimated_mean_size_if_bin_1_lect:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompute the results above for the following two variations:\n",
    "- $V = 250$ instead of the original $500$;\n",
    "- the distribution of job sizes is uniform with $a = 0$ an $b = 2000$ instead of exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altv = 250\n",
    "estimated_prob_bin_1_altv = est_prob_bin_1(samples_lect, altv)\n",
    "estimated_prob_under_q_if_bin_1_altv = est_prob_under_q_if_bin_1(samples_lect, altv, w_lect)\n",
    "estimated_mean_size_if_bin_1_altv = est_mean_size_if_bin_1(samples_lect, altv)\n",
    "print(\n",
    "    f\"P(job is in bin 1) = {estimated_prob_bin_1_altv:.4f}\",\n",
    "    f\"P(job size < W | job is in bin 1) = {estimated_prob_under_q_if_bin_1_altv:.4f}\",\n",
    "    f\"E[job size | job is in bin 1] = {estimated_mean_size_if_bin_1_altv:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_altu = RNG.uniform(low=0, high=2000, size=t_jobs)\n",
    "estimated_prob_bin_1_altu = est_prob_bin_1(samples_altu, v_lect)\n",
    "estimated_prob_under_q_if_bin_1_altu = est_prob_under_q_if_bin_1(samples_altu, altv, w_lect)\n",
    "estimated_mean_size_if_bin_1_altu = est_mean_size_if_bin_1(samples_altu, v_lect)\n",
    "print(\n",
    "    f\"P(job is in bin 1) = {estimated_prob_bin_1_altu:.4f}\",\n",
    "    f\"P(job size < W | job is in bin 1) = {estimated_prob_under_q_if_bin_1_altu:.4f}\",\n",
    "    f\"E[job size | job is in bin 1] = {estimated_mean_size_if_bin_1_altu:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
